train_config: MathTrainingConfig(model_name_or_path='google/gemma-3-1b-it', use_flash_attention=False, load_in_8bit=False, batch_size=1, gradient_accumulation_steps=32, epochs=1, learning_rate=2e-05, weight_decay=0.0, warmup_ratio=0.03, max_grad_norm=1.0, gradient_checkpointing=True, max_seq_length=1024, max_answer_length=None, method='way0', pissa_rank=16, pissa_alpha=16.0, lora_dropout=0.0, orthogonality_weight=0.001, regularization_type='log_determinant', steps_per_phase=0, total_cycles=2, low_rank_r=4, quantize_residual=False, quantize_base_components=False, target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'], dataset='metamath', data_path='./data', preprocessing_num_workers=4, zero_prompt_loss=True, filter_disclaimers=True, evaluation_strategy='single', num_eval_samples=3, eval_temperature=0.8, eval_top_p=0.95, use_vllm=True, eval_batch_size=4, use_wandb=True, project_name='rotational-pissa-llm-math', experiment_name=None, output_dir='./outputs', save_checkpoints=True, logging_steps=10, eval_steps=100, save_steps=500, device='cuda', freeze_backbone=True, train_embeddings=False, train_lm_head=False, seed=42)
‚úì Using device: cuda
‚ö†Ô∏è tokenizer.pad_token is already: <pad>
‚úì Loaded tokenizer: google/gemma-3-1b-it
  Vocab size: 262145
  PAD token: <pad> (ID: 0)
  EOS token: <eos> (ID: 1)
 ‚ö†Ô∏è  Initial Padding side: right

üìö Loading Datasets...
  Training dataset: metamath
  Loading MetaMathQA dataset (filtering GSM category)...
  Filtering GSM category samples (using consistent prompt format)...
Processing MetaMathQA:   0%|          | 0/395000 [00:00<?, ?it/s]Processing MetaMathQA:   0%|          | 329/395000 [00:00<02:00, 3287.35it/s]Processing MetaMathQA:   0%|          | 686/395000 [00:00<01:54, 3449.40it/s]Processing MetaMathQA:   0%|          | 1047/395000 [00:00<01:51, 3520.37it/s]Processing MetaMathQA:   0%|          | 1401/395000 [00:00<01:51, 3524.64it/s]Processing MetaMathQA:   0%|          | 1764/395000 [00:00<01:50, 3561.98it/s]Processing MetaMathQA:   1%|          | 2132/395000 [00:00<01:49, 3598.52it/s]Processing MetaMathQA:   1%|          | 2515/395000 [00:00<01:46, 3672.48it/s]Processing MetaMathQA:   1%|          | 2883/395000 [00:00<01:46, 3674.69it/s]Processing MetaMathQA:   1%|          | 3244/395000 [00:00<01:48, 3605.79it/s]
  ‚úì Collected 1000 train + 1000 eval GSM category samples
‚úì Loaded 1000 train examples from metamath
‚úì Loaded 1000 test examples from metamath
  Intermediate eval: 1000 samples from MetaMathQA validation

üéØ Final Evaluation Dataset: GSM8K test set
‚úì Loaded 8792 full examples from gsm8k
  Final evaluation will use 8792 samples from GSM8K test set
wandb: Currently logged in as: chandan22140 (chandan22140-indraprastha-institute-of-information-techn) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run i7awasv4
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/chandan/DL_Quantization/backup_131/DL_Quantization/PiSSA/test_current/wandb/run-20260106_130944-i7awasv4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run metamath_way0_seed42
wandb: ‚≠êÔ∏è View project at https://wandb.ai/chandan22140-indraprastha-institute-of-information-techn/rotational-pissa-llm-math
wandb: üöÄ View run at https://wandb.ai/chandan22140-indraprastha-institute-of-information-techn/rotational-pissa-llm-math/runs/i7awasv4

======================================================================
üöÄ TRAINING: WAY0
======================================================================


======================================================================
Creating model with method: way0
======================================================================
Loading base model: google/gemma-3-1b-it
`torch_dtype` is deprecated! Use `dtype` instead!
  Capturing original weight norms...

üìê Model Architecture:
  Total parameters: 999,885,952 (999.89M)

üîÑ Applying Rotational PiSSA (way0)...
  Found 182 layers to replace
  [10/182] Processing layers...
  [20/182] Processing layers...
  [30/182] Processing layers...
  [40/182] Processing layers...
  [50/182] Processing layers...
  [60/182] Processing layers...
  [70/182] Processing layers...
  [80/182] Processing layers...
  [90/182] Processing layers...
  [100/182] Processing layers...
  [110/182] Processing layers...
  [120/182] Processing layers...
  [130/182] Processing layers...
  [140/182] Processing layers...
  [150/182] Processing layers...
  [160/182] Processing layers...
  [170/182] Processing layers...
  [180/182] Processing layers...
  [182/182] Processing layers...
  ‚úì Created 182 rotational adapters
  ‚úì Embeddings frozen
  ‚úì LM head frozen

üìä Parameter Counts:
  Total:     999,885,952 (999.89M)
  Trainable: 96,096 (0.10M)
  Frozen:    999,789,856 (999.79M)
  Trainable: 0.01%
  ‚úì Created RotationalPiSSATrainer for orthogonality regularization

üîç VRAM Profiling:

======================================================================
üîç VRAM MEMORY BREAKDOWN (ENHANCED)
======================================================================

üéØ GPU Device: cuda:0
‚ö° Mixed Precision: ENABLED (FP16/BF16 detected)

üìä Overall VRAM Usage:
  Current Allocated: 1989.68 MB (1.943 GB)
  Peak Allocated:    2161.63 MB (2.111 GB)
  Total Reserved:    2008.00 MB (1.961 GB)
  Fragmentation:     18.32 MB (0.018 GB)
  CUDA Context:      ~300 MB (estimated baseline overhead)

üî• Trainable Parameters:
  Count:   96,096
  Memory:  0.18 MB

üßä Frozen Parameters:
  Count:   999,885,952
  Memory:  1907.13 MB

üì¶ Buffers (non-parameters):
  Memory:  24.88 MB

‚öôÔ∏è  Estimated Optimizer States (AdamW):
  Memory:  0.73 MB
  (Mixed precision: 4√ó trainable params - states stored in FP32)

üé® Precision Distribution:
  FP16:  0.18 MB
  BF16:  1907.14 MB

‚ùì Activations/Temporary Buffers/Unaccounted:
  Memory:  -243.25 MB
  (allocated - params - buffers - optimizer - CUDA context)
  ‚ö†Ô∏è  Note: Gradient memory not explicitly tracked (may be in this bucket)

üí° Activations typically include:
  - Forward pass intermediate tensors
  - Attention scores and values
  - Batch normalization statistics
  - Dropout masks
  - Gradients (if backward pass executed)

üìã Large Parameters (>1MB):
  model.embed_tokens.weight                           576.00 MB  (262144, 1152)                 frozen     torch.bfloat16
  model.layers.0.mlp.gate_proj.base_layer.weight       15.19 MB  (6912, 1152)                   frozen     torch.bfloat16
  model.layers.0.mlp.up_proj.base_layer.weight         15.19 MB  (6912, 1152)                   frozen     torch.bfloat16
  model.layers.0.mlp.down_proj.base_layer.weight       15.19 MB  (1152, 6912)                   frozen     torch.bfloat16
  model.layers.1.mlp.gate_proj.base_layer.weight       15.19 MB  (6912, 1152)                   frozen     torch.bfloat16
  model.layers.1.mlp.up_proj.base_layer.weight         15.19 MB  (6912, 1152)                   frozen     torch.bfloat16
  model.layers.1.mlp.down_proj.base_layer.weight       15.19 MB  (1152, 6912)                   frozen     torch.bfloat16
  model.layers.2.mlp.gate_proj.base_layer.weight       15.19 MB  (6912, 1152)                   frozen     torch.bfloat16
  model.layers.2.mlp.up_proj.base_layer.weight         15.19 MB  (6912, 1152)                   frozen     torch.bfloat16
  model.layers.2.mlp.down_proj.base_layer.weight       15.19 MB  (1152, 6912)                   frozen     torch.bfloat16

======================================================================
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
üìã Training Configuration:
  Epochs: 1
  Batch size: 1
  Gradient accumulation: 32
  Effective batch size: 32
  Learning rate: 2e-05
  Warmup ratio: 0.03
  0%|          | 0/32 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/chandan/DL_Quantization/backup_131/DL_Quantization/PiSSA/test_current/train_llm_rotational.py", line 1847, in <module>
    main()
  File "/home/chandan/DL_Quantization/backup_131/DL_Quantization/PiSSA/test_current/train_llm_rotational.py", line 1843, in main
    trainer.train_single_method(config.method)
  File "/home/chandan/DL_Quantization/backup_131/DL_Quantization/PiSSA/test_current/train_llm_rotational.py", line 1236, in train_single_method
    train_result = trainer.train()
  File "/home/chandan/miniconda3/envs/pissa/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/home/chandan/miniconda3/envs/pissa/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/chandan/miniconda3/envs/pissa/lib/python3.10/site-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/home/chandan/DL_Quantization/backup_131/DL_Quantization/PiSSA/test_current/train_llm_rotational.py", line 1201, in compute_loss
    loss, outputs = super().compute_loss(model, inputs, return_outputs, num_items_in_batch)
  File "/home/chandan/miniconda3/envs/pissa/lib/python3.10/site-packages/torch/_tensor.py", line 1171, in __iter__
    raise TypeError("iteration over a 0-d tensor")
TypeError: iteration over a 0-d tensor
Traceback (most recent call last):
  File "/home/chandan/DL_Quantization/backup_131/DL_Quantization/PiSSA/test_current/train_llm_rotational.py", line 1847, in <module>
    main()
  File "/home/chandan/DL_Quantization/backup_131/DL_Quantization/PiSSA/test_current/train_llm_rotational.py", line 1843, in main
    trainer.train_single_method(config.method)
  File "/home/chandan/DL_Quantization/backup_131/DL_Quantization/PiSSA/test_current/train_llm_rotational.py", line 1236, in train_single_method
    train_result = trainer.train()
  File "/home/chandan/miniconda3/envs/pissa/lib/python3.10/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
  File "/home/chandan/miniconda3/envs/pissa/lib/python3.10/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/chandan/miniconda3/envs/pissa/lib/python3.10/site-packages/transformers/trainer.py", line 4020, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/home/chandan/DL_Quantization/backup_131/DL_Quantization/PiSSA/test_current/train_llm_rotational.py", line 1201, in compute_loss
    loss, outputs = super().compute_loss(model, inputs, return_outputs, num_items_in_batch)
  File "/home/chandan/miniconda3/envs/pissa/lib/python3.10/site-packages/torch/_tensor.py", line 1171, in __iter__
    raise TypeError("iteration over a 0-d tensor")
TypeError: iteration over a 0-d tensor
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mmetamath_way0_seed42[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260106_130944-i7awasv4/logs[0m
